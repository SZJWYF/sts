{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from DataUtil import *\n",
    "from my_model_p import *\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def save_data_to_pkl(data, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def load_data_from_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "afqmc_benchmarkReader= AFQMCBenchmarkReader(data_path=\"OPPO-xiaobu\")\n",
    "train_sentence_pairs, train_scores, dev_sentence_pairs, dev_scores = afqmc_benchmarkReader.get_data()\n",
    "\n",
    "\n",
    "bert_file_path = \"bert-chinese\"\n",
    "external_embed_dim = 200\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_file_path)\n",
    "bert_model = BertModel.from_pretrained(bert_file_path).to(device)\n",
    "\n",
    "sentences_dict = load_data_from_pkl('OPPO-xiaobu/OPPOxiaobu_sentence_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lcqmc_train_Dataset = STSDataset(train_sentence_pairs, train_scores, tokenizer, sentences_dict)\n",
    "lcqmc_dev_Dataset = STSTestDataset(dev_sentence_pairs, dev_scores, tokenizer, sentences_dict)\n",
    "\n",
    "lcqmc_train_loader = DataLoader(lcqmc_train_Dataset, batch_size=64, shuffle=True)\n",
    "lcqmc_dev_loader = DataLoader(lcqmc_dev_Dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model loading...\")\n",
    "myModel = SimilarityModel(bert_model,200).to(device)# 确保模型在GPU上\n",
    "# myModel.load_state_dict(torch.load('/data/szj/sts/transformers/SZJ_Model/STSModel.pth'))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        # 使用 tqdm 包裹数据加载器，显示进度条\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, scores, sentence1_words_embeddings, sentence2_words_embeddings = batch\n",
    "            input_ids = inputs['input_ids'].squeeze(1).to(device)  # 移动到GPU\n",
    "            attention_mask = inputs['attention_mask'].squeeze(1).to(device)\n",
    "            scores = scores.float()\n",
    "            scores = scores.to(device)  # 移动到GPU\n",
    "            scores = scores.unsqueeze(1)\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.float()\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.float()\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.to(device)\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask,\n",
    "                            sentence1_words_embeddings,\n",
    "                            sentence2_words_embeddings)\n",
    "            loss = criterion(outputs, scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "        evaluate_model_p(myModel, test_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, scores, sentence1_words_embeddings, sentence2_words_embeddings = batch\n",
    "            input_ids = inputs['input_ids'].squeeze(1).to(device)  # 移动到GPU\n",
    "            attention_mask = inputs['attention_mask'].squeeze(1).to(device)\n",
    "            scores = scores.to(device)  # 移动到GPU\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.to(device)\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                            sentence1_words_embeddings=sentence1_words_embeddings,\n",
    "                            sentence2_words_embeddings=sentence2_words_embeddings)\n",
    "            loss = criterion(outputs, scores)\n",
    "            total_loss += loss.item()\n",
    "    test_loss = total_loss / len(data_loader)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    return test_loss\n",
    "\n",
    "def evaluate_model_p(model, data_loader):\n",
    "    model.eval()\n",
    "    ture_num = 0\n",
    "    total_num = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, scores, sentence1_words_embeddings, sentence2_words_embeddings = batch\n",
    "            input_ids = inputs['input_ids'].squeeze(1).to(device)  # 移动到GPU\n",
    "            attention_mask = inputs['attention_mask'].squeeze(1).to(device)\n",
    "            scores = scores.float()\n",
    "            scores = scores.to(device)  # 移动到GPU\n",
    "            scores = scores.unsqueeze(1)\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.float()\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.float()\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.to(device)\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask,\n",
    "                            sentence1_words_embeddings,\n",
    "                            sentence2_words_embeddings)\n",
    "            loss = criterion(outputs, scores)\n",
    "            total_loss += loss.item()\n",
    "            for i in range(len(outputs)):\n",
    "                if float(outputs[i]) > 0.5:\n",
    "                    score = 1\n",
    "                else:\n",
    "                    score = 0\n",
    "                if int(scores[i]) == score:\n",
    "                    ture_num += 1\n",
    "                total_num += 1\n",
    "    test_loss = total_loss / len(data_loader)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print('Accuracy: '+str(ture_num/total_num))\n",
    "    accuracy = ture_num/total_num\n",
    "    loss_list.append(test_loss)\n",
    "    global best_loss\n",
    "    global best_model\n",
    "    if test_loss <= best_loss:\n",
    "        best_loss = test_loss\n",
    "        best_model = model\n",
    "    print(\"best:\"+str(best_loss))\n",
    "\n",
    "# Training the model\n",
    "print(\"Training...\")\n",
    "best_loss=1000.0\n",
    "loss_list = []\n",
    "print(\"Training...\")\n",
    "optimizer = optim.Adam(myModel.parameters(), lr=2e-5)\n",
    "train_model(myModel, lcqmc_train_loader, lcqmc_dev_loader,criterion, optimizer, epochs=5)\n",
    "myModel = best_model\n",
    "print('-------------')\n",
    "optimizer = optim.Adam(myModel.parameters(), lr=1e-5)\n",
    "train_model(myModel, lcqmc_train_loader, lcqmc_dev_loader,criterion, optimizer, epochs=5)\n",
    "myModel = best_model\n",
    "optimizer = optim.Adam(myModel.parameters(), lr=1e-6)\n",
    "train_model(myModel, lcqmc_train_loader, lcqmc_dev_loader,criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(myModel, lcqmc_train_loader, lcqmc_dev_loader,criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_p(model, data_loader):\n",
    "    model.eval()\n",
    "    ture_num = 0\n",
    "    total_num = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs, scores, sentence1_words_embeddings, sentence2_words_embeddings = batch\n",
    "            input_ids = inputs['input_ids'].squeeze(1).to(device)  # 移动到GPU\n",
    "            attention_mask = inputs['attention_mask'].squeeze(1).to(device)\n",
    "            scores = scores.float()\n",
    "            scores = scores.to(device)  # 移动到GPU\n",
    "            scores = scores.unsqueeze(1)\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.float()\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.float()\n",
    "            sentence1_words_embeddings = sentence1_words_embeddings.to(device)\n",
    "            sentence2_words_embeddings = sentence2_words_embeddings.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask,\n",
    "                            sentence1_words_embeddings,\n",
    "                            sentence2_words_embeddings)\n",
    "            loss = criterion(outputs, scores)\n",
    "            total_loss += loss.item()\n",
    "            for i in range(len(outputs)):\n",
    "                if float(outputs[i]) > 0.6:\n",
    "                    score = 1\n",
    "                else:\n",
    "                    score = 0\n",
    "                if int(scores[i]) == score:\n",
    "                    ture_num += 1\n",
    "                total_num += 1\n",
    "    test_loss = total_loss / len(data_loader)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print('Accuracy: '+str(ture_num/total_num))\n",
    "    accuracy = ture_num/total_num\n",
    "    loss_list.append(test_loss)\n",
    "    global best_loss\n",
    "    global best_model\n",
    "    if test_loss <= best_loss:\n",
    "        best_loss = test_loss\n",
    "        best_model = model\n",
    "    print(\"best:\"+str(best_loss))\n",
    "evaluate_model_p(myModel,lcqmc_dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
