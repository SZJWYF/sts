{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:50:15.416137Z",
     "start_time": "2024-08-16T01:50:15.319672Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from DataUtil import *\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    # 定义一个正则表达式模式，用于匹配所有中英文标点符号\n",
    "    pattern = r'[^\\w\\s]'\n",
    "    # 使用 re.sub() 函数将匹配的标点符号替换为空字符串\n",
    "    cleaned_sentence = re.sub(pattern, '', sentence)\n",
    "    return cleaned_sentence\n",
    "\n",
    "OPPOxiaobuReader = OPPOxiaobuBenchmarkReader('OPPO-xiaobu')\n",
    "train_sentence_pairs, train_scores, dev_sentence_pairs, dev_scores = OPPOxiaobuReader.get_data()\n",
    "\n",
    "# sentence_list = LCQMC_train_sentence_pairs+LCQMC_dev_sentence_pairs+LCQMC_test_sentence_pairs\n",
    "sentence_list = train_sentence_pairs  + dev_sentence_pairs\n",
    "def save_data_to_pkl(data, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "def load_data_from_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea10965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('maidalun/bce-embedding-base_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9223ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from BCEmbedding import EmbeddingModel\n",
    "# \n",
    "# # list of sentences\n",
    "# sentences = ['sentence_0', 'sentence_1']\n",
    "# \n",
    "# # init embedding model\n",
    "# model = EmbeddingModel(model_name_or_path=\"/data/.rootcache/modelscope/hub/maidalun/bce-embedding-base_v1\")\n",
    "# \n",
    "# # extract embeddings\n",
    "# embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed314ddc539cba4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:58:21.231124Z",
     "start_time": "2024-08-16T01:50:18.483100Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 替换成你的词库文件路径\n",
    "file_path = 'tencent800w/tencent-ailab-embedding-zh-d200-v0.2.0/tencent-ailab-embedding-zh-d200-v0.2.0.txt'\n",
    "# 加载词库\n",
    "model = KeyedVectors.load_word2vec_format(file_path, binary=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d804acea0eac6e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:58:21.445680Z",
     "start_time": "2024-08-16T01:58:21.233114Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "# jieba.enable_paddle()# 启动paddle模式。 0.40版之后开始支持，早期版本不支持\n",
    "seg_list = list(jieba.cut(\"我手机丢了，我想换个手机\", cut_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b57c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:58:21.450001Z",
     "start_time": "2024-08-16T01:58:21.446278Z"
    }
   },
   "outputs": [],
   "source": [
    "seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7af43399d2db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:58:55.782632Z",
     "start_time": "2024-08-16T01:58:21.451063Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "word_vector_length = 200\n",
    "# 保证 n 为 50\n",
    "n = 50\n",
    "sentence_dict={}\n",
    "for sentence1,sentence2 in tqdm(sentence_list):\n",
    "    seg_list1 = list(jieba.cut(remove_punctuation(sentence1), cut_all=True))\n",
    "    # 获取模型中每个词的向量\n",
    "    sentence_embedding1 = []\n",
    "    embeddings =[]\n",
    "    for word in seg_list1:\n",
    "        try:\n",
    "            embeddings.append(model[word])\n",
    "        except:\n",
    "            embeddings.append(np.zeros(word_vector_length))\n",
    "    if len(sentence_embedding1) > n:\n",
    "        # 如果超过 50 个词，只取前 50 个词\n",
    "        sentence_embedding1 = sentence_embedding1[:n]\n",
    "    else:\n",
    "        # 如果少于 50 个词，用零向量补充\n",
    "        padding_length = n - len(sentence_embedding1)\n",
    "        sentence_embedding1.extend([np.zeros(word_vector_length)] * padding_length)\n",
    "    # 最终的句子向量矩阵为 50 x 200\n",
    "    sentence_matrix1 = np.array(sentence_embedding1)\n",
    "    sentence_matrix1 = csr_matrix(sentence_matrix1)\n",
    "    sentence_dict[remove_punctuation(sentence1)] = sentence_matrix1\n",
    "    \n",
    "    seg_list2 = list(jieba.cut(remove_punctuation(sentence2), cut_all=True))\n",
    "    # 获取模型中每个词的向量\n",
    "    sentence_embedding2 = []\n",
    "    embeddings =[]\n",
    "    for word in seg_list2:\n",
    "        try:\n",
    "            embeddings.append(model[word])\n",
    "        except:\n",
    "            embeddings.append(np.zeros(word_vector_length))\n",
    "    if len(sentence_embedding2) > n:\n",
    "        # 如果超过 50 个词，只取前 50 个词\n",
    "        sentence_embedding2 = sentence_embedding2[:n]\n",
    "    else:\n",
    "        # 如果少于 50 个词，用零向量补充\n",
    "        padding_length = n - len(sentence_embedding2)\n",
    "        sentence_embedding2.extend([np.zeros(word_vector_length)] * padding_length)\n",
    "    # 最终的句子向量矩阵为 50 x 200\n",
    "    sentence_matrix2 = np.array(sentence_embedding2)\n",
    "    sentence_matrix2 = csr_matrix(sentence_matrix2)\n",
    "    sentence_dict[remove_punctuation(sentence2)] = sentence_matrix2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e59b8f75161cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T01:58:57.250860Z",
     "start_time": "2024-08-16T01:58:55.783281Z"
    }
   },
   "outputs": [],
   "source": [
    "save_data_to_pkl(sentence_dict, 'OPPOxiaobu_sentence_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681e0c6e1fadfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
